{"cells":[{"cell_type":"code","metadata":{"id":"ltBAm-vu2T9C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"44191be8-27e8-492a-8c28-772ca878bd88","executionInfo":{"status":"ok","timestamp":1587565358278,"user_tz":-120,"elapsed":1012,"user":{"displayName":"William JACQUES","photoUrl":"","userId":"16955981879199111082"}}},"source":["%cd \"drive/My Drive/darknet\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oaTDH91U2ctY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"490b8f07-0da6-42d1-e9a8-44c7475a3c61","executionInfo":{"status":"ok","timestamp":1587565363857,"user_tz":-120,"elapsed":5050,"user":{"displayName":"William JACQUES","photoUrl":"","userId":"16955981879199111082"}}},"source":["%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_8OdQ0x-mG9g","colab_type":"text"},"source":["# Detect and save cropped image"]},{"cell_type":"markdown","metadata":{"id":"GmJqxdhe3j7y","colab_type":"text"},"source":["#### Utils:"]},{"cell_type":"code","metadata":{"id":"OXslsB5CEWY_","colab_type":"code","colab":{}},"source":["import os\n","import glob\n","import time\n","\n","import cv2\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","\n","class Cropper:\n","\n","    def __init__(self, cfg: str, weights: str, thresh: float = 0.5):\n","        \"\"\"\n","        Load model from config and weights file\n","        \"\"\"\n","        self.cfg = cfg\n","        self.weights = weights\n","        self.CONFTHRESH = thresh  # set to 0.3 if not working\n","        self.NMSTHRESH = 0.3\n","        self.model = cv2.dnn.readNetFromDarknet(self.cfg, self.weights)\n","        print(\"- Model ready\")\n","\n","    \n","    def __show_dif(self, img, crop):\n","        \"\"\"\n","        Returns subplots with original and cropped images\n","        \"\"\"\n","        _, ax = plt.subplots(1, 2, figsize=(8, 4))\n","        ax[0].set_title('Predicted image')\n","        ax[0].imshow(img)\n","        ax[1].set_title('Cropped image')\n","        ax[1].imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n","        plt.show()\n","\n","    def __crop(self, img):\n","        \"\"\"\n","        Get prediction and return cropped image\n","        \"\"\"\n","        (H, W) = img.shape[:2]\n","        layer_names = self.model.getLayerNames()\n","        layer_names = [\n","            layer_names[i[0] - 1] for i in self.model.getUnconnectedOutLayers()\n","        ]\n","\n","        blob = cv2.dnn.blobFromImage(\n","            img,\n","            1 / 255.0,\n","            (416, 416),\n","            swapRB=False,\n","            crop=False\n","        )\n","\n","        self.model.setInput(blob)\n","        layer_outputs = self.model.forward(layer_names)\n","\n","        boxes = []\n","        confidences = []\n","        classes_ids = []\n","\n","        for output in tqdm(layer_outputs, desc=\"- Making prediction\"):\n","\n","            for detected in output:\n","\n","                scores = detected[5:]\n","                class_id = np.argmax(scores)\n","                conf = scores[class_id]\n","\n","                if conf > self.CONFTHRESH:\n","                    box = detected[0:4] * np.array([W, H, W, H])\n","                    (x_center, y_center, width, height) = box.astype(\"int\")\n","\n","                    x = int(x_center - (width / 2))\n","                    y = int(y_center - (height / 2))\n","\n","                    boxes.append(\n","                        [x, y, int(width), int(height)]\n","                    )\n","                    confidences.append(float(conf))\n","                    classes_ids.append(class_id)\n","\n","        idxs = cv2.dnn.NMSBoxes(\n","            boxes,\n","            confidences,\n","            self.CONFTHRESH,\n","            self.NMSTHRESH\n","        )\n","\n","        if len(idxs) > 0:\n","\n","            for i in idxs.flatten():\n","\n","                (x, y) = (max(0, boxes[i][0]), max(0, boxes[i][1]))\n","                (w, h) = (boxes[i][2], boxes[i][3])\n","                cropped_image = img[y:y+h, x:x+w]\n","\n","        return cropped_image\n","\n","\n","\n","    def predict(self, item: str):\n","        \"\"\"\n","        Predict one image or a folder of images and save result\n","        \"\"\"\n","        if '.jpg' in item:\n","\n","            image = plt.imread(item)\n","            # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","            start = time.time()\n","            output_image = self.__crop(img=image)\n","            print(f\"- Predicted {item} in {time.time() - start:.2f} seconds\")\n","\n","            output_path = os.path.join('predictions/', os.path.basename(item))\n","\n","            output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n","\n","            cv2.imwrite(output_path, output_image)\n","\n","            print(f\"- Saved predicted image to {output_path}\")\n","            self.__show_dif(image, output_image)\n","\n","        else:\n","\n","            for i in glob.glob(os.path.join(item, '*.jpg')):\n","\n","                image = plt.imread(i)\n","                # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","                start = time.time()\n","                output_image = self.__crop(img=image)\n","                print(f\"- Predicted {i} in {time.time() - start:.2f} seconds\")\n","\n","                output_path = os.path.join('predictions/', os.path.basename(i))\n","\n","                output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n","\n","                cv2.imwrite(output_path, output_image)\n","\n","                print(f\"- Saved predicted image to {output_path}\")\n","                self.__show_dif(image, output_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zWN8MrVE3jEJ","colab_type":"text"},"source":["#### Run:"]},{"cell_type":"code","metadata":{"id":"yBdecRcMJqKy","colab_type":"code","colab":{}},"source":["del crop"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdM4kJdWmKsz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"45e33623-34a5-46ea-c397-1d5b7f667a6e","executionInfo":{"status":"ok","timestamp":1587567391336,"user_tz":-120,"elapsed":592,"user":{"displayName":"William JACQUES","photoUrl":"","userId":"16955981879199111082"}}},"source":["crop = Cropper(\n","    cfg='cfg/custom/tiny-armoire.cfg',\n","    weights='backup/tiny-armoire_last.weights',\n","    thresh=0.5\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXfuv6Y_H8Ip","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"32d73d7d-9a96-4fc4-dc0a-f88153005f59"},"source":["crop.predict(\"data/obj/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHl3xhN2IHDX","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"drive_detect.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1-T_SuOklQU1Eu3Yl8o8VadLI6FiaP_b1","authorship_tag":"ABX9TyMwsNsguF6+QWCGBbKKxGGw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}